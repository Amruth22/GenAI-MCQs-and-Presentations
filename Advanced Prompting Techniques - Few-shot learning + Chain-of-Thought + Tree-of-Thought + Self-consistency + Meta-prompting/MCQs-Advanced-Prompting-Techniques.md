# MCQ Questions - Advanced Prompting Techniques

## Instructions
Choose the best answer for each question. Each question has only one correct answer.

---

### Question 1
What is few-shot learning in the context of LLMs?

A) Training with very little data  
B) Providing a few examples in the prompt to guide the model's behavior  
C) Using small models  
D) Fast training methods  

**Answer: B**

---

### Question 2
What does Chain-of-Thought (CoT) prompting encourage?

A) Faster responses  
B) Step-by-step reasoning and intermediate thinking steps  
C) Shorter answers  
D) Random generation  

**Answer: B**

---

### Question 3
What is the key advantage of Chain-of-Thought prompting?

A) Reduced computational cost  
B) Improved performance on complex reasoning tasks  
C) Faster inference  
D) Smaller model requirements  

**Answer: B**

---

### Question 4
What does Tree-of-Thought (ToT) prompting enable?

A) Linear thinking only  
B) Exploring multiple reasoning paths and backtracking when needed  
C) Faster processing  
D) Simpler responses  

**Answer: B**

---

### Question 5
How does Tree-of-Thought differ from Chain-of-Thought?

A) ToT is faster  
B) ToT allows branching and exploring multiple reasoning paths simultaneously  
C) ToT uses fewer tokens  
D) ToT is simpler  

**Answer: B**

---

### Question 6
What is self-consistency in prompting?

A) Using the same prompt repeatedly  
B) Generating multiple reasoning paths and selecting the most consistent answer  
C) Maintaining prompt format  
D) Using consistent vocabulary  

**Answer: B**

---

### Question 7
What does meta-prompting involve?

A) Using metadata  
B) Prompts that instruct the model on how to construct or modify other prompts  
C) Faster prompting  
D) Shorter prompts  

**Answer: B**

---

### Question 8
What is zero-shot prompting?

A) No examples provided  
B) Asking the model to perform a task without providing examples  
C) Fast execution  
D) No training required  

**Answer: B**

---

### Question 9
What is the purpose of providing examples in few-shot prompting?

A) To increase prompt length  
B) To demonstrate the desired input-output format and behavior  
C) To slow down processing  
D) To confuse the model  

**Answer: B**

---

### Question 10
What does "Let's think step by step" typically trigger in LLMs?

A) Faster responses  
B) More detailed reasoning and intermediate steps  
C) Shorter answers  
D) Random outputs  

**Answer: B**

---

### Question 11
What is the main benefit of self-consistency over single-path reasoning?

A) Faster processing  
B) Higher accuracy by aggregating multiple reasoning attempts  
C) Simpler implementation  
D) Lower computational cost  

**Answer: B**

---

### Question 12
What does Tree-of-Thought prompting require for effective implementation?

A) Simple linear prompts  
B) Systematic exploration and evaluation of different reasoning branches  
C) Minimal computational resources  
D) Short response times  

**Answer: B**

---

### Question 13
What is prompt engineering?

A) Hardware optimization  
B) The practice of designing effective prompts to elicit desired responses from LLMs  
C) Model architecture design  
D) Data preprocessing  

**Answer: B**

---

### Question 14
What does "in-context learning" refer to?

A) Learning during training  
B) The model's ability to learn and adapt from examples provided in the prompt  
C) Contextual embeddings  
D) Learning from context windows  

**Answer: B**

---

### Question 15
What is the role of delimiters in prompting?

A) To add decoration  
B) To clearly separate different parts of the prompt for better structure  
C) To increase token count  
D) To slow down processing  

**Answer: B**

---

### Question 16
What does "prompt chaining" involve?

A) Connecting hardware  
B) Using the output of one prompt as input to another prompt  
C) Linking multiple models  
D) Chaining training processes  

**Answer: B**

---

### Question 17
What is the purpose of role-playing in prompts?

A) Entertainment only  
B) Instructing the model to adopt a specific persona or expertise for better responses  
C) Increasing complexity  
D) Reducing accuracy  

**Answer: B**

---

### Question 18
What does "temperature" control in prompt-based generation?

A) Processing speed  
B) The randomness and creativity of the model's responses  
C) Model size  
D) Memory usage  

**Answer: B**

---

### Question 19
What is the benefit of using structured prompts?

A) Longer responses  
B) More consistent and predictable outputs from the model  
C) Faster training  
D) Reduced accuracy  

**Answer: B**

---

### Question 20
What does "prompt injection" refer to?

A) Medical procedures  
B) Malicious attempts to manipulate model behavior through crafted prompts  
C) Hardware installation  
D) Data insertion  

**Answer: B**

---

### Question 21
What is the purpose of providing context in prompts?

A) To increase token usage  
B) To give the model relevant background information for better responses  
C) To slow down processing  
D) To confuse the model  

**Answer: B**

---

### Question 22
What does "prompt tuning" optimize?

A) Hardware performance  
B) The prompt itself rather than model parameters  
C) Training speed  
D) Model architecture  

**Answer: B**

---

### Question 23
What is the advantage of multi-step prompting?

A) Simpler implementation  
B) Breaking complex tasks into manageable steps for better accuracy  
C) Faster execution  
D) Reduced token usage  

**Answer: B**

---

### Question 24
What does "constitutional AI" prompting involve?

A) Legal documents  
B) Training models to follow a set of principles or constitution in their responses  
C) Government regulations  
D) Constitutional law  

**Answer: B**

---

### Question 25
What is the purpose of negative prompting?

A) Creating negative content  
B) Explicitly instructing the model what not to do or include  
C) Reducing model performance  
D) Generating criticism  

**Answer: B**

---

### Question 26
What does "prompt compression" aim to achieve?

A) File size reduction  
B) Maintaining effectiveness while reducing prompt length and token usage  
C) Faster typing  
D) Simpler language  

**Answer: B**

---

### Question 27
What is "retrieval-augmented prompting"?

A) Prompt storage  
B) Enhancing prompts with relevant information retrieved from external sources  
C) Prompt backup  
D) Prompt archiving  

**Answer: B**

---

### Question 28
What does "adversarial prompting" test?

A) Model speed  
B) Model robustness and potential vulnerabilities  
C) Model size  
D) Model accuracy  

**Answer: B**

---

### Question 29
What is the benefit of using examples with explanations in few-shot prompting?

A) Longer prompts  
B) Helping the model understand not just what to do but why  
C) Increased complexity  
D) Slower processing  

**Answer: B**

---

### Question 30
What does "prompt ensembling" involve?

A) Musical arrangements  
B) Combining multiple prompts or prompt variations to improve results  
C) Group prompting  
D) Prompt collections  

**Answer: B**

---

## Answer Key Summary
1. B  2. B  3. B  4. B  5. B  
6. B  7. B  8. B  9. B  10. B  
11. B  12. B  13. B  14. B  15. B  
16. B  17. B  18. B  19. B  20. B  
21. B  22. B  23. B  24. B  25. B  
26. B  27. B  28. B  29. B  30. B  

---

**Total Questions: 30**  
**Topics Covered:** Few-shot Learning, Chain-of-Thought, Tree-of-Thought, Self-consistency, Meta-prompting, and Advanced Prompt Engineering